:_content-type: PROCEDURE
[id="Configuring_virtual_numa_{context}"]
= Configuring Virtual NUMA

In the Administration Portal, you can configure virtual NUMA nodes on a virtual machine and pin them to physical NUMA nodes on one or more hosts. The hostâ€™s default policy is to schedule and run virtual machines on any available resources on the host. As a result, the resources backing a large virtual machine that cannot fit within a single host socket could be spread out across multiple NUMA nodes. Over time these resources may be moved around, leading to poor and unpredictable performance. Configure and pin virtual NUMA nodes to avoid this outcome and improve performance.

Configuring virtual NUMA requires a NUMA-enabled host. To confirm whether NUMA is enabled on a host, log in to the host and run `numactl --hardware`. The output of this command should show at least two NUMA nodes. You can also view the host's NUMA topology in the Administration Portal by selecting the host from the *Hosts* tab and clicking *NUMA Support*. This button is only available when the selected host has at least two NUMA nodes.

[NOTE]
====
If you define *NUMA Pinning*, the default migration mode is *Allow manual migration only* by default.
====


*Configuring Virtual NUMA*

. Click menu:Compute[Virtual Machines] and select a virtual machine.
. Click btn:[Edit].
. Click btn:[Show Advanced Options].
. Click the *Host* tab.
. Select the *Specific Host(s)* radio button and select the host(s) from the list. The selected host(s) must have at least two NUMA nodes.
. Click *NUMA Pinning*.
. In the *NUMA Topology* window, click and drag virtual NUMA nodes from the box on the right to host NUMA nodes on the left as required, and click btn:[OK].
. Select *Strict*, *Preferred*, or *Interleave* from the *Tune Mode* drop-down list in each NUMA node. If the selected mode is *Preferred*, the *NUMA Node Count* must be set to `1`.
. You can also set the NUMA pinning policy automatically by selecting an *Auto Pinning Policy* from the drop-down list:
+
* *None* - makes no changes to the virtual machine.
//* *Pin* - uses the existing CPU topology that has been set, in order to configure CPU pinning and NUMA pinning.
* *Resize and Pin* - maximizes the CPU topology and generates the CPU pinning and NUMA pinning configurations.
. Click btn:[OK].

[NOTE]
====
If you do not pin the virtual NUMA node to a host NUMA node, the system defaults to the NUMA node that contains the host device's memory-mapped I/O (MMIO), provided that there are one or more host devices and all of those devices are from a single NUMA node.
====
