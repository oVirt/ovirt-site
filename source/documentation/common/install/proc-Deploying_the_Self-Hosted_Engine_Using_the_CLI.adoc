[id='Deploying_the_Self-Hosted_Engine_Using_the_CLI_{context}']
= Deploying the Self-Hosted Engine Using the Command Line

// Included in:
// Installing {virt-product-fullname} as a self-hosted engine using the command line

:cli_deploy:

You can deploy a self-hosted engine from the command line. After installing the setup package, you run the command `hosted-engine --deploy`, and a script collects the details of your environment and uses them to configure the host and the {engine-name}.

.Prerequisites

* FQDNs prepared for your {engine-name} and the host. Forward and reverse lookup records must both be set in the DNS.
* When using a block storage domain, either FCP or iSCSI, a single target LUN is the only supported setup for a self-hosted engine.


.Procedure

. Install the deployment tool:
+
----
# yum install ovirt-hosted-engine-setup
----
+
. Use the `tmux` window manager to run the script to avoid losing the session in case of network or terminal disruption.
+
Install and run `tmux`:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# yum -y install tmux
# tmux
----
. Start the deployment script:
+
----
# hosted-engine --deploy
----
+
[NOTE]
====
To escape the script at any time, use the kbd:[Ctrl+D] keyboard combination to abort deployment. In the event of session timeout or connection disruption, run `screen -d -r` to recover the deployment session.
====
. When prompted, enter *Yes* to begin the deployment:
+
----
Continuing will configure this host for serving as hypervisor and will create a local VM with a running engine.
The locally running engine will be used to configure a new storage domain and create a VM there.
At the end the disk of the local VM will be moved to the shared storage.
Are you sure you want to continue? (Yes, No)[Yes]:
----
+
. Configure the network. Check that the gateway shown is correct and press kbd:[Enter]. Enter a pingable address on the same subnet so the script can check the host's connectivity.
+
----
Please indicate a pingable gateway IP address [X.X.X.X]:
----
+
. The script detects possible NICs to use as a management bridge for the environment. Enter one of them or press kbd:[Enter] to accept the default.
+
----
Please indicate a nic to set ovirtmgmt bridge on: (eth1, eth0) [eth1]:
----
+
. If you want to use a custom appliance for the virtual machine installation, enter the path to the OVA archive. Otherwise, leave this field empty to use the {engine-appliance-name}.
+
[options="nowrap" subs="normal"]
----
If you want to deploy with a custom engine appliance image,
please specify the path to the OVA archive you would like to use
(leave it empty to skip, the setup will use {engine-package}-appliance rpm installing it if missing):
----
+
. Enter the virtual machine's CPU and memory configuration:
+
----
Please specify the number of virtual CPUs for the VM (Defaults to appliance OVF value): [4]:
Please specify the memory size of the VM in MB (Defaults to maximum available): [7267]:
----
+
. Specify the FQDN for the {engine-name} virtual machine, such as `manager.example.com`:
+
[options="nowrap" subs="normal"]
----
Please provide the FQDN you would like to use for the engine appliance.
Note: This will be the FQDN of the engine VM you are now going to launch,
it should not point to the base host or to any other existing machine.
Engine VM FQDN:
----
+
. Specify the domain of the {engine-name} virtual machine. For example, if the FQDN is `manager.example.com`, then enter `example.com`.
+
----
Please provide the domain name you would like to use for the engine appliance.
Engine VM domain: [example.com]
----
+
. Create the root password for the {engine-name}, and reenter it to confirm:
+
----
Enter root password that will be used for the engine appliance:
Confirm appliance root password:
----
+
. Optionally, enter an SSH public key to enable you to log in to the {engine-name} as the root user without entering a password, and specify whether to enable SSH access for the root user:
+
----
Enter ssh public key for the root user that will be used for the engine appliance (leave it empty to skip):
Do you want to enable ssh access for the root user (yes, no, without-password) [yes]:
----
+
. Enter a MAC address for the {engine-name} virtual machine, or accept a randomly generated one. If you want to provide the {engine-name} virtual machine with an IP address via DHCP, ensure that you have a valid DHCP reservation for this MAC address. The deployment script will not configure the DHCP server for you.
+
----
You may specify a unicast MAC address for the VM or accept a randomly generated default [00:16:3e:3d:34:47]:
----
. Enter the virtual machine's networking details:
+
----
How should the engine VM network be configured (DHCP, Static)[DHCP]?
----
+
If you specified *Static*, enter the IP address of the {engine-name}:
+
[IMPORTANT]
====
* The static IP address must belong to the same subnet as the host. For example, if the host is in 10.1.1.0/24, the {engine-name} virtual machine's IP must be in the same subnet range (10.1.1.1-254/24).
* For IPv6, {virt-product-fullname} supports only static addressing.
====
+
----
Please enter the IP address to be used for the engine VM [x.x.x.x]:
Please provide a comma-separated list (max 3) of IP addresses of domain name servers for the engine VM
Engine VM DNS (leave it empty to skip):
----
+
. Specify whether to add entries for the {engine-name} virtual machine and the base host to the virtual machine's `/etc/hosts` file. You must ensure that the host names are resolvable.
+
----
Add lines for the appliance itself and for this host to /etc/hosts on the engine VM?
Note: ensuring that this host could resolve the engine VM hostname is still up to you (Yes, No)[No]
----
+
. Provide the name and TCP port number of the SMTP server, the email address used to send email notifications, and a comma-separated list of email addresses to receive these notifications. Alternatively, press kbd:[Enter] to accept the defaults:
+
----
Please provide the name of the SMTP server through which we will send notifications [localhost]:
Please provide the TCP port number of the SMTP server [25]:
Please provide the email address from which notifications will be sent [root@localhost]:
Please provide a comma-separated list of email addresses which will get notifications [root@localhost]:
----
+
. Create a password for the `admin@internal` user to access the Administration Portal and reenter it to confirm:
+
----
Enter engine admin password:
Confirm engine admin password:
----
+
The script creates the virtual machine. This can take some time if it needs to install the {engine-appliance-name}. After creating the virtual machine, the script continues to gather information.
+
. Select the type of storage to use:
+
----
Please specify the storage you would like to use (glusterfs, iscsi, fc, nfs)[nfs]:
----
+
* For NFS, enter the version, full address and path to the storage, and any mount options:
+
[options="nowrap" subs="normal"]
----
Please specify the nfs version you would like to use (auto, v3, v4, v4_1)[auto]:
Please specify the full shared storage connection path to use (example: host:/path): _storage.example.com:/hosted_engine/nfs_
If needed, specify additional mount options for the connection to the hosted-engine storage domain []:
----
+
* For iSCSI, enter the portal details and select a target and LUN from the auto-detected lists. You can only select one iSCSI target during the deployment, but multipathing is supported to connect all portals of the same portal group.
+
[NOTE]
====
To specify more than one iSCSI target, you must enable multipathing before deploying the self-hosted engine. See link:{URL_rhel_docs_legacy}html-single/dm_multipath/[_{enterprise-linux} DM Multipath_] for details. There is also a link:https://access.redhat.com/labs/multipathhelper/#/[Multipath Helper] tool that generates a script to install and configure multipath with different options.
====
+
----
Please specify the iSCSI portal IP address:
Please specify the iSCSI portal port [3260]:
Please specify the iSCSI discover user:
Please specify the iSCSI discover password:
Please specify the iSCSI portal login user:
Please specify the iSCSI portal login password:

The following targets have been found:
	[1]	iqn.2017-10.com.redhat.example:he
		TPGT: 1, portals:
			192.168.1.xxx:3260
			192.168.2.xxx:3260
			192.168.3.xxx:3260

Please select a target (1) [1]: 1

The following luns have been found on the requested target:
  [1] 360003ff44dc75adcb5046390a16b4beb   199GiB  MSFT   Virtual HD
      status: free, paths: 1 active

Please select the destination LUN (1) [1]:
----
+
* For Gluster storage, enter the full address and path to the storage, and any mount options:
+
[IMPORTANT]
====
Only replica 1 and replica 3 Gluster storage are supported. Ensure you configure the volume as follows:

[options="nowrap" subs="normal"]
----
gluster volume set _VOLUME_NAME_ group virt
gluster volume set _VOLUME_NAME_ performance.strict-o-direct on
gluster volume set _VOLUME_NAME_ network.remote-dio off
gluster volume set _VOLUME_NAME_ storage.owner-uid 36
gluster volume set _VOLUME_NAME_ storage.owner-gid 36
gluster volume set _VOLUME_NAME_ network.ping-timeout 30
----
====
+
[options="nowrap" subs="normal"]
----
Please specify the full shared storage connection path to use (example: host:/path): _storage.example.com:/hosted_engine/gluster_volume_
If needed, specify additional mount options for the connection to the hosted-engine storage domain []:
----
+
* For Fibre Channel, select a LUN from the auto-detected list. The host bus adapters must be configured and connected, and the LUN must not contain any existing data. To reuse an existing LUN, see link:{URL_virt_product_docs}administration_guide/index.html[Reusing LUNs] in the _Administration Guide_.
+
----
The following luns have been found on the requested target:
[1] 3514f0c5447600351   30GiB   XtremIO XtremApp
		status: used, paths: 2 active

[2] 3514f0c5447600352   30GiB   XtremIO XtremApp
		status: used, paths: 2 active

Please select the destination LUN (1, 2) [1]:
----
+
. Enter the {engine-name} disk size:
+
----
Please specify the size of the VM disk in GB: [50]:
----
+
When the deployment completes successfully, one data center, cluster, host, storage domain, and the {engine-name} virtual machine are already running. You can log in to the Administration Portal to add any other resources.
+
. Optionally, add a directory server using the `ovirt-engine-extension-aaa-ldap-setup` interactive setup script so you can add additional users to the environment. For more information, see link:{URL_virt_product_docs}administration_guide/index.html[Configuring an External LDAP Provider] in the _Administration Guide_.

The {engine-name} virtual machine, the host running it, and the self-hosted engine storage domain are flagged with a gold crown in the Administration Portal.

:cli_deploy!:
