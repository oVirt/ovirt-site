:_content-type: PROCEDURE
[id='Deploying_the_Self-Hosted_Engine_Using_the_CLI_{context}']
= Deploying the self-hosted engine using the command line

// Included in:
// Installing {virt-product-fullname} as a self-hosted engine using the command line

:cli_deploy:

You can deploy a self-hosted engine from the command line. After installing the setup package, you run the command `hosted-engine --deploy`, and a script collects the details of your environment and uses them to configure the host and the {engine-name}.

You can customize the {engine-name} virtual machine during deployment, either manually, by pausing the deployment, or using automation.

* Setting the variable `he_pause_host` to `true` pauses deployment after installing the {engine-name} and adding the deployment host to the {engine-name}.
* Setting the variable `he_pause_before_engine_setup` to `true` pauses the deployment before installing the {engine-name} and before restoring the {engine-name} when using `he_restore_from_file`.
+
[NOTE]
====
When the `he_pause_host` or `he_pause_before_engine_setup` variables are set to true a lock file is created at `/tmp` with the suffix `_he_setup_lock` on the deployment host. You can then manually customize the virtual machine as needed. The deployment continues after you delete the lock file, or after 24 hours, whichever comes first.
====
* Adding an Ansible playbook to any of the following directories on the deployment host automatically runs the playbook. Add the playbook under one of the following directories under `/usr/share/ansible/collections/ansible_collections/redhat/rhv/roles/hosted_engine_setup/hooks/`:

** `enginevm_before_engine_setup`
** `enginevm_after_engine_setup`
** `after_add_host`
** `after_setup`


.Prerequisites

* Upgrade the appliance content to the latest product version before performing `engine-setup`.
** To do this manually, pause the deployment using `he_pause_before_engine_setup` and perform a `dnf update`.
** To do this automatically, apply the `enginevm_before_engine_setup` hook.
* FQDNs prepared for your {engine-name} and the host. Forward and reverse lookup records must both be set in the DNS.
* When using a block storage domain, either FCP or iSCSI, a single target LUN is the only supported setup for a self-hosted engine.
* Optional: If you want to customize the {engine-name} virtual machine during deployment using automation, an Ansible playbook must be added. See xref:customizing_engine_vm_during_deployment_auto_SHE_cli_deploy[Customizing the Engine virtual machine using automation during deployment].
* The self-hosted engine setup script requires ssh public key access using 2048-bit RSA keys from the engine virtual machine to the root account of its bare metal host. In `/etc/ssh/sshd_config`, these values must be set as follows:
** `PubkeyAcceptedKeyTypes` must allow 2048-bit RSA keys or stronger.
+
By default, this setting uses system-wide crypto policies. For more information, see the manual page `crypto-policies(7)`.
+
[NOTE]
====
{hypervisor-shortname} hosts that are registered with the {engine-name} in versions earlier than 4.4.5.5 require RSA 2048 for backward compatibility until all the keys are migrated.

{hypervisor-shortname} hosts registered for 4.4.5.5 and later use the strongest algorithm that is supported by both the {engine-name} and {hypervisor-shortname}. The `PubkeyAcceptedKeyTypes` setting helps determine which algorithm is used.
====
** `PermitRoolLogin` is set to `without-password` or `yes`
** `PubkeyAuthentication` is set to `yes`

.Procedure

. Install the deployment tool:
+
[source,terminal,subs="normal"]
----
# dnf install ovirt-hosted-engine-setup
----

. Use the `tmux` window manager to run the script to avoid losing the session in case of network or terminal disruption.
+
Install and run `tmux`:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# dnf -y install tmux
# tmux
----
. Start the deployment script:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# hosted-engine --deploy
----
+
Alternatively, to pause the deployment after adding the deployment host to the {engine-name}, use the command line option [command]`--ansible-extra-vars=he_pause_host=true`:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# hosted-engine --deploy --ansible-extra-vars=he_pause_host=true
----
+
[NOTE]
====
To escape the script at any time, use the kbd:[Ctrl+D] keyboard combination to abort deployment. In the event of session timeout or connection disruption, run `tmux attach` to recover the deployment session.
====

. When prompted, enter *Yes* to begin the deployment:
+
[source,terminal,subs="normal"]
----
Continuing will configure this host for serving as hypervisor and will create a local VM with a running engine.
The locally running engine will be used to configure a new storage domain and create a VM there.
At the end the disk of the local VM will be moved to the shared storage.
Are you sure you want to continue? (Yes, No)[Yes]:
----

. Configure the network. Check that the gateway shown is correct and press kbd:[Enter]. Enter a pingable address on the same subnet so the script can check the host's connectivity.
+
[source,terminal,subs="normal"]
----
Please indicate a pingable gateway IP address [X.X.X.X]:
----

. The script detects possible NICs to use as a management bridge for the environment. Enter one of them or press kbd:[Enter] to accept the default.
+
[source,terminal,subs="normal"]
----
Please indicate a nic to set ovirtmgmt bridge on: (ens1, ens0) [ens1]:
----

. Specify how to check network connectivity. The default is `dns`.
+
[source,terminal,subs="normal"]
----
Please specify which way the network connectivity should be checked (ping, dns, tcp, none) [dns]:
----
+
`*ping*`:: Attempts to ping the gateway.
`*dns*`:: Checks the connection to the DNS server.
`*tcp*`:: Creates a TCP connection to a host and port combination. You need to specify a destination IP address and port. Once the connection is successfully created, the network is considered to be alive. Ensure that the given host is able to accept incoming TCP connections on the given port.
`*none*`:: The network is always considered connected.

. Enter a name for the data center in which to deploy the host for the self-hosted engine. The default name is *Default*.
+
[source,terminal,subs="normal"]
----
Please enter the name of the data center where you want to deploy this hosted-engine host.
Data center [Default]:
----

. Enter a name for the cluster in which to deploy the host for the self-hosted engine. The default name is *Default*.
+
[source,terminal,subs="normal"]
----
Please enter the name of the cluster where you want to deploy this hosted-engine host.
Cluster [Default]:
----

. If you want to use a custom appliance for the virtual machine installation, enter the path to the OVA archive. Otherwise, leave this field empty to use the {engine-appliance-name}.
. To deploy with a custom {engine-appliance-name} appliance image, specify the path to the OVA archive. Otherwise, leave this field empty to use the {engine-appliance-name}.
+
[source,terminal,subs="normal"]
----
If you want to deploy with a custom engine appliance image, please specify the path to the OVA archive you would like to use.
 Entering no value will use the image from the rhvm-appliance rpm, installing it if needed.
 Appliance image path []:
----

. Enter the CPU and memory configuration for the {engine-name} virtual machine:
+
[source,terminal,subs="normal"]
----
Please specify the number of virtual CPUs for the VM. The default is the appliance OVF value [4]:
Please specify the memory size of the VM in MB. The default is the maximum available [6824]:
----

. Specify the FQDN for the {engine-name} virtual machine, such as `manager.example.com`:
+
[source,terminal,subs="normal"]
----
Please provide the FQDN you would like to use for the engine.
Note: This will be the FQDN of the engine VM you are now going to launch,
it should not point to the base host or to any other existing machine.
Engine VM FQDN []:
----

. Specify the domain of the {engine-name} virtual machine. For example, if the FQDN is `manager.example.com`, then enter `example.com`.
+
[source,terminal,subs="normal"]
----
Please provide the domain name you would like to use for the engine appliance.
Engine VM domain: [example.com]
----

. Create the root password for the {engine-name}, and reenter it to confirm:
+
[source,terminal,subs="normal"]
----
Enter root password that will be used for the engine appliance:
Confirm appliance root password:
----
+
. Optional: Enter an SSH public key to enable you to log in to the {engine-name} virtual machine as the root user without entering a password, and specify whether to enable SSH access for the root user:
+
[source,terminal,subs="normal"]
----
You may provide an SSH public key, that will be added by the deployment script to the authorized_keys file of the root user in the engine appliance.
This should allow you passwordless login to the engine machine after deployment.
If you provide no key, authorized_keys will not be touched.
SSH public key []:

Do you want to enable ssh access for the root user (yes, no, without-password) [yes]:
----

. Optional: You can apply the DISA STIG security profile on the {engine-name} virtual machine. The DISA STIG profile is the default OpenSCAP profile.
+
----
Do you want to apply a default OpenSCAP security profile? (Yes, No) [No]:
----

. Enter a MAC address for the {engine-name} virtual machine, or accept a randomly generated one. If you want to provide the {engine-name} virtual machine with an IP address via DHCP, ensure that you have a valid DHCP reservation for this MAC address. The deployment script will not configure the DHCP server for you.
+
[source,terminal,subs="normal"]
----
You may specify a unicast MAC address for the VM or accept a randomly generated default [00:16:3e:3d:34:47]:
----

. Enter the {engine-name} virtual machine's networking details:
+
[source,terminal,subs="normal"]
----
How should the engine VM network be configured (DHCP, Static)[DHCP]?
----
+
If you specified *Static*, enter the IP address of the {engine-name} virtual machine:
+
[IMPORTANT]
====
* The static IP address must belong to the same subnet as the host. For example, if the host is in 10.1.1.0/24, the {engine-name} virtual machine's IP must be in the same subnet range (10.1.1.1-254/24).
* For IPv6, {virt-product-fullname} supports only static addressing.
====
+
[source,terminal,subs="normal"]
----
Please enter the IP address to be used for the engine VM [x.x.x.x]:
Please provide a comma-separated list (max 3) of IP addresses of domain name servers for the engine VM
Engine VM DNS (leave it empty to skip):
----

. Specify whether to add entries for the {engine-name} virtual machine and the base host to the virtual machine's `/etc/hosts` file. You must ensure that the host names are resolvable.
+
[source,terminal,subs="normal"]
----
Add lines for the appliance itself and for this host to /etc/hosts on the engine VM?
Note: ensuring that this host could resolve the engine VM hostname is still up to you.
Add lines to /etc/hosts? (Yes, No)[Yes]:
----

. Provide the name and TCP port number of the SMTP server, the email address used to send email notifications, and a comma-separated list of email addresses to receive these notifications. Alternatively, press kbd:[Enter] to accept the defaults:
+
[source,terminal,subs="normal"]
----
Please provide the name of the SMTP server through which we will send notifications [localhost]:
Please provide the TCP port number of the SMTP server [25]:
Please provide the email address from which notifications will be sent [root@localhost]:
Please provide a comma-separated list of email addresses which will get notifications [root@localhost]:
----

. Create a password for the `admin@internal` user to access the Administration Portal and reenter it to confirm:
+
[source,terminal,subs="normal"]
----
Enter engine admin password:
Confirm engine admin password:
----

. Specify the hostname of the deployment host:
+
[source,terminal,subs="normal"]
----
Please provide the hostname of this host on the management network [hostname.example.com]:
----
+
The script creates the virtual machine. By default, the script first downloads and installs the {engine-appliance-name}, which increases the installation time.

. Optional: If you set the variable `he_pause_host: true`, the deployment pauses after adding the deployment host to the {engine-name}. You can now log in from the deployment host to the {engine-name} virtual machine to customize it. You can log in with either the FQDN or the IP address of the {engine-name}. For example, if the FQDN of the {engine-name} is `manager.example.com`:
+
[source,terminal,subs="normal"]
----
$ ssh \root@manager.example.com
----
+
[TIP]
====
In the installation log, the IP address is in `local_vm_ip`. The installation log is the most recent instance of `/var/log/ovirt-hosted-engine-setup/ovirt-hosted-engine-setup-ansible-bootstrap_local_vm*`.
====
+
.. Customize the {engine-name} virtual machine as needed.
.. When you are done, log in to the Administration Portal using a browser with the {engine-name} FQDN and make sure that the host's state is *Up*.
.. Delete the lock file and the deployment script automatically continues, configuring the {engine-name} virtual machine.

.  Select the type of storage to use:
+
[source,terminal,subs="normal"]
----
Please specify the storage you would like to use (glusterfs, iscsi, fc, nfs)[nfs]:
----
+
* For NFS, enter the version, full address and path to the storage, and any mount options:
+
[source,terminal,subs="normal"]
----
Please specify the nfs version you would like to use (auto, v3, v4, v4_1)[auto]:
Please specify the full shared storage connection path to use (example: host:/path): _storage.example.com:/hosted_engine/nfs_
If needed, specify additional mount options for the connection to the hosted-engine storage domain []:
----
+
* For iSCSI, enter the portal details and select a target and LUN from the auto-detected lists. You can only select one iSCSI target during the deployment, but multipathing is supported to connect all portals of the same portal group.
+
[NOTE]
====
To specify more than one iSCSI target, you must enable multipathing before deploying the self-hosted engine. See link:{URL_rhel_docs_legacy}html-single/dm_multipath/[_{enterprise-linux} DM Multipath_] for details. There is also a link:https://access.redhat.com/labs/multipathhelper/#/[Multipath Helper] tool that generates a script to install and configure multipath with different options.
====
+
----
Please specify the iSCSI portal IP address:
Please specify the iSCSI portal port [3260]:
Please specify the iSCSI discover user:
Please specify the iSCSI discover password:
Please specify the iSCSI portal login user:
Please specify the iSCSI portal login password:

The following targets have been found:
	[1]	iqn.2017-10.com.redhat.example:he
		TPGT: 1, portals:
			192.168.1.xxx:3260
			192.168.2.xxx:3260
			192.168.3.xxx:3260

Please select a target (1) [1]: 1

The following luns have been found on the requested target:
  [1] 360003ff44dc75adcb5046390a16b4beb   199GiB  MSFT   Virtual HD
      status: free, paths: 1 active

Please select the destination LUN (1) [1]:
----
+
* For Gluster storage, enter the full address and path to the storage, and any mount options:
+
[IMPORTANT]
====
Only replica 1 and replica 3 Gluster storage are supported. Ensure you configure the volume as follows:

[source,terminal,subs="normal"]
----
gluster volume set _VOLUME_NAME_ group virt
gluster volume set _VOLUME_NAME_ performance.strict-o-direct on
gluster volume set _VOLUME_NAME_ network.remote-dio off
gluster volume set _VOLUME_NAME_ storage.owner-uid 36
gluster volume set _VOLUME_NAME_ storage.owner-gid 36
gluster volume set _VOLUME_NAME_ network.ping-timeout 30
----
====
+
[source,terminal,subs="normal"]
----
Please specify the full shared storage connection path to use (example: host:/path): _storage.example.com:/hosted_engine/gluster_volume_
If needed, specify additional mount options for the connection to the hosted-engine storage domain []:
----
+
* For Fibre Channel, select a LUN from the auto-detected list. The host bus adapters must be configured and connected, and the LUN must not contain any existing data. To reuse an existing LUN, see link:{URL_virt_product_docs}{URL_format}administration_guide/index#Reusing_LUNs[Reusing LUNs] in the _Administration Guide_.
+
----
The following luns have been found on the requested target:
[1] 3514f0c5447600351   30GiB   XtremIO XtremApp
		status: used, paths: 2 active

[2] 3514f0c5447600352   30GiB   XtremIO XtremApp
		status: used, paths: 2 active

Please select the destination LUN (1, 2) [1]:
----

. Enter the disk size of the {engine-name} virtual machine:
+
----
Please specify the size of the VM disk in GB: [50]:
----
+
When the deployment completes successfully, one data center, cluster, host, storage domain, and the {engine-name} virtual machine are already running. You can log in to the Administration Portal to add any other resources.

. Optional: Install and configure Red Hat Single Sign On so that you can add additional users to the environment. For more information, see link:{URL_virt_product_docs}{URL_format}administration_guide/index#Configuring_Red_Hat_SSO[Installing and Configuring Red Hat Single Sign-On] in the _Administration Guide_.
. Optional: Deploy Grafana so you can monitor and display reports from your {virt-product-shortname} environment.
For more information, see link:{URL_virt_product_docs}{URL_format}administration_guide/index#configuring_grafana[Configuring Grafana] in the _Administration Guide_.

The {engine-name} virtual machine, the host running it, and the self-hosted engine storage domain are flagged with a gold crown in the Administration Portal.

[NOTE]
====
Both the {engine-name}'s I/O scheduler and the hypervisor that hosts the {engine-name} reorder I/O requests. This double reordering might delay I/O requests to the storage layer, impacting performance.

Depending on your data center, you might improve performance by changing the I/O scheduler to `none`. For more information, see link:{URL_rhel_docs_latest}html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance[Available disk schedulers] in _Monitoring and managing system status and performance_ for RHEL.
====

:cli_deploy!:
